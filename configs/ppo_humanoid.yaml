# Configuration PPO pour Humanoid
algorithm:
  name: "PPO"
  learning_rate: 3.0e-4
  n_steps: 2048
  batch_size: 64
  n_epochs: 10
  gamma: 0.99
  gae_lambda: 0.95
  clip_range: 0.2
  ent_coef: 0.0
  vf_coef: 0.5
  max_grad_norm: 0.5

network:
  pi: [256, 256, 128]  # Actor
  vf: [256, 256, 128]  # Critic
  activation: "relu"

training:
  total_timesteps: 10_000_000
  n_envs: 8  # Avec une 4080, tu peux monter Ã  16
  eval_freq: 10000
  save_freq: 50000
  log_interval: 1

environment:
  name: "Humanoid-v5"
  terminate_when_unhealthy: true
  healthy_z_range: [1.0, 2.0]